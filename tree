/usr/src/sys/uvm
|-- uvm.h 
	* Contains global uvm state data
        - uvm struct contains global state data
            1. page_active      - queue of allocated pages in use, protected by uvm.pageqlock 
            2. page_inactive    - queue of inactive pages, protected by uvm.pageqlock 
            3. pageqlock        - mutex protecting page queues above 
            4. fpageqlock       - mutex protecting free page queue and pdaemon 
            5. page_init_done   - bool indicating if uvm_page_init() is finished
            6. pmr_control      - pmemrange data(see uvm_pmemrange.h desc)
            7. pagedaemon       - flag that triggers page daemon 
            8. pagedaemon_proc  - pagedaemon's pid 
            9. aidoned          - flag that triggers an async I/O daemon I believe
           10. aidoned_proc     - async I/O pid
           11. aidoned_lock     - mutex protecting async I/O daemon(specifically aio_done field below)
           12. kentry_free      - singly linked list head of free page pool.
           13. aio_done         - tail queue of buffers for finished async i/o requests.
                                  protected by aiodoned_lock.
           14. kernel_object    - uvm object that backs anonymous kernel memory usage
	    - Entry type bits for indicating properties of map entries
            1. UVM_ET_OBJ           - it is a uvm_object
            2. UVM_ET_SUBMAP        - it is a vm_map submap
            3. UVM_ET_COPYONWRITE   - copy_on_write      
            4. UVM_ET_NEEDSCOPY     - needs_copy         
            5. UVM_ET_HOLE          - no backend         
            6. UVM_ET_NOFAULT       - don't fault        
            7. UVM_ET_STACK         - this is a stack    
            8. UVM_ET_WC            - write combining    
            9. UVM_ET_CONCEAL       - omit from dumps    
           10. UVM_ET_SYSCALL       - syscall text segment
           11. UVM_ET_IMMUTABLE     - entry may not be changed 
           12. UVM_ET_FREEMAPPED    - map entry is on free list (DEBUG)
        - UVM_ET_ISX - macros for each of the above, with X in {OBJ, ..., CONCEAL}
		- Some uvm_addr decls(unsure if these should be here)
        - NOTE: VMMAP_FREE_START and VMMAP_FREE_END give the starting and ending addresses of free space
                in an entry. These defs show that this can be derived from adding the guard to the end
                address and adding the guard and fspace to the end respectfully, so the start and end
                is what is currently allocated by the entry 
|-- uvm_addr.c
|-- uvm_addr.h
	* Contains prototypes of uvm addr selector funcs and ds
		- NOTE: Addr selectors are different algorithms that decide where
		  to put addresses. They are defined by a struct containing 
		  an interface(struct of function pointers) and some state
		  data(max and min addrs). The interface has a few methods
		  for selecting, freeing, and printing addresses. There are
		  5 different selectors atm:
			1. uaddr_lin: unsure, disabled by default
			2. uaddr_rnd: random algo addrs
			3. uaddr_bestfit: bestfit algo addrs
			4. uaddr_pivot: pivot algo addrs(patch this)
			5. uaddr_stack_brk: selector for the stack/heap section
		  Also has selectors for kernel bootstrap, which uses an RBTree 
	      for something.
        - uvm_addr_state captures basic state of selectors
            1. uaddr_minaddr    - min address in selection range (page-aligned)
            2. uaddr_maxaddr    - max address in selection range (page-aligned)
            3. uaddr_functions  - interface that all selectors must implement
        - uvm_addr_functions describes the interface all selectors implement
            1. uaddr_select      - an address selection algorithm
            2. uaddr_free_insert - a freelist insertion function(optional)
            3. uaddr_free_remove - a freelist deletion function(optional)
            4. uaddr_destroy     - a destructor for the algorithm state
            5. uaddr_print       - print function for debugging
            6. uaddr_name        - cstring name of allocator
        - uaddr_free_rbtree is defiend and prototyped here(see uvm_map.h).
|-- uvm_amap.c
    * Implementation of the API in uvm_amap.h
        - Globals
            1. Pools(they use an allocator that goes through kernel uobj to avoid infinite loop)
                i. uvm_amap_pool         - global vm_amap pool
               ii. uvm_small_amap_pool   - global vm_amap pool array of size UVM_AMAP_CHUNK
                    a. An array so pools can rep differing slot sizes, i.e. uvm_small_amap_pool[i] 
                       is a pool of small amaps that has # slots = i + 1
              iii. uvm_amap_chunk_pool   - global vm_amap_chunk pool
               iv. amap_small_pool_names - names for each small pool, max 9 characters
            2. Amap List
                i. amap_list       - global list of vm_amaps
               ii. amap_list_lock  - rw_lock protecting amap_list 
        - Local Functions
            1. (vm_amap *)amap_alloc1(int slots, int waitf, int lazyalloc)
                * Allocate an amap, but do not initialize the overlay
                    => lock is not set
                0.  set pwaitf = (waitf & M_WAITOK) ? PR_WAITOK : PR_NOWAIT, set chunkperbucket = 1, hashshift = 0
                    - basically, convert memory api wait flag to pool api wait flag
                1. find # of chunks by finding the closest multiple of UVM_AMAP_CHUNK above slots and
                   dividing by UVM_AMAP_CHUNK 
                2. if lazyalloc is set ***INVESTIGATE THIS: FUNC NEVER USES PROPER BUCKET COUNT***
                    i. calculate logchunks, which is equal to floor(log_2(chunks)), or equivalently
                       the 1 start position of the highest bit set to 1, with the 0 case being 
                       defined to 1.
                   ii. calculate chunkperbucket, which is the highest power of 2 less than logchunks,
                       and hashshift, which is the number that satisfied chunkperbucket = 1 << hashshift
                       or equivalently log_2(chunksperbucket)
                3. after checking 2, if slots is greater than UVM_AMAP_CHUNK, allocate a regular
                   sized amap, else allocate a small amap from the respective slot sized pool
                   (pool_get), use pwaitf for flags, return NULL if this fails.
                      - in small amap case or pwaitf with PR_ZERO, which zeros 
                        the object, though unsure why not used in other case
                4. Init amap  
                    i. set am_lock to NULL
                   ii. set am_ref = 1, since creation is an implicit reference
                  iii. set am_ppref to NULL if UVM_AMAP_PPREF defined
                   iv. set am_nslot to slots
                    v. set am_nused to 0
                   vi. if small amap(UVM_AMAP_SMALL), set am_small.ac_nslot to slots, return amap here
                  vii. set am_ncused = 0
                 viii. init the am_chunks tail queue (TAILQ_INIT)
                   ix. set am_hashshift = hashshift 
                    x. init am_buckets 
                        a. find how many buckets are needed (howmany(chunks, chunkperbucket))
                        b. allocate am_buckets array 
                           (mallocarray(buckets, sizeof(*amap->am_buckets), M_UVMAMP, waitf | lazyalloc ? M_ZERO : 0))
                        c. if step b alloc fails, goto step 6
                        d. set am_nbuckets = bucket count from a
                5. If not lazyalloc, fill buckets
                    i. For each index i in buckets 
                   ii. Determine number of slots n
                        a. If we are not at last bucket us UVM_AMAP_CHUNK
                        b. If we are at last bucket, calculate slots % UVM_AMAP_CHUNK. If
                           this val is 0, we have enough slots for buckets * UVM_AMAP_CHUNK
                           so set n =  UVM_AMAP_CHUNK. If not, we have exactly slots % UVM_AMAP_CHUNK
                           left over, so these will go to the last bucket 
                  iii. allocate the chunk (pool_get) and goto step 6 if this fails (pool_get)
                   iv. init the chunk
                        a. set am_buckets[i] to this chunk
                        b. increment am_ncused
                        c. set ac_baseslot to i * UVM_AMAP_CHUNK
                        d. set ac_nslot to n from step ii.
                        e. insert chunk into ac_list (TAILQ_INSERT_TAIL)
                6. Reach here if failed
                    i. free am_buckets (free(amap->am_buckets, M_UVMAMAP, buckets * sizeof(*amap->am_buckets)))
                   ii. loop through am_chunks (TAILQ_FOREACH_SAFE) and free chunks (pool_put)
                  iii. free amap (pool_put)
                   iv. return NULL
            2. (void)amap_list_insert(vm_amap *)
                * Inserts an amap into am_list
                1. lock amap list (amap_lock_list)   
                2. insert amap (LIST_INSERT_HEAD)   
                3. unlock amap list (amap_unlock_list)   
            3. (void)amap_list_remove( vm_amap *)
                * Removes an amap from am_list
                1. lock amap list (amap_lock_list)   
                2. remove amap (LIST_REMOVE)   
                3. unlock amap list (amap_unlock_list)   
            4. (vm_amap_chunk *)amap_chunk_get(vm_amap *, int slot, int create, int waitf)
                * lookup a chunk for slot. if create is non-zero, the chunk is created if it
                  does not exist yet
                    => returns the chunk on success or NULL on error
                1. If amap is a small amap, return the only chunk (UVM_AMAP_SMALL)
                2. Else, search the chunk in list 
                    i. find bucket for slot in amap (UVM_AMAP_BUCKET)
                   ii. find base_slot for slot (AMAP_BASE_SLOT)
                  iii. start at the first chunk in bucket, and traverse
                       ac_list(TAILQ_NEXT), stopping if chunk is NULL, or the bucket
                       for the baseslot of the current chunk is not the bucket
                       for out slot(means we traveresed the entire bucket)(UVM_AMAP_BUCKET), 
                       store previous chunk on each iteration. If the baseslot
                       of the current chunk is the base slot from step ii. return this chunk.
                3. Else, if not create, return NULL
                4. Else, if create, make and insert a chunk for this slot                 
                    i. Determine # of slots chunk can hold (chunk->ac_nslot)
                        a. if amap->am_nslot - baseslot from 2.i. is greater
                           than or equal to a UVM_AMAP_CHUNK, set # of slots to UVM_AMAP_CHUNK
                        b. else set size to amap->am_nslot - baseslot
                   ii. Get a newchunk from pool and use waitf as flag, return NULL if this fails(pool_get)
                  iii. If there was not a previous chunk, this chunk is the header of a new bucket,
                       so insert it into the back of ac_list(TAILQ_INSERT_TAIL) and set am_buckets[bucket] = newchunk
                   iv. Else, insert newchunk in ac_list after previous chunk(TAILQ_INSERT_AFTER)
                    v. increment am_ncused
                   vi. set ac_baseslot to the baseslot found earlier
                  vii. set ac_nslot to the value found in 4.i.
                 viii. return the new chunk
            5. (void)amap_chunk_free(vm_amap *, vm_amap_chunk *)
                * free a chunk if amap is not small
                1. if amap is small, return
                2. find bucket for chunk using ac_baseslot (UVM_AMAP_BUCKET)
                3. find next chunk(TAILQ_NEXT) and store it, denote nchunk 
                4. if this chunk is a bucket header
                    i. if next chunk exists and its in the bucket(UVM_AMAP_BUCKET on nchunk->baseslot),
                       set the bucket header to the next chunk  
                   ii. else set the bucket header to NULL
                5. put the chunk back into the amap chunk pool (pool_put)
                6. decrement amap->am_ncused
            6. (void)amap_lock_alloc(struct vm_amap *)
                * allocs a lock from the amap ***NO PROTOTYPE***
                1. alloc a lock at amap->am_lock (rw_obj_alloc)
        - Ppref management local funcs 
            * ppref is an optional amap feature, enabled by defining
              UVM_AMAP_PPREF, which keeps trakc of reference counts on a per-page basis. It is managed
              by an array of ints, which in the event of a failed allocation, will set the array to PPREF_NONE
              and continue normal operation with ppref functionality. refs are managed in page sized chunks. 
              For chunks of length 1(one page long), the int at that index in the array is simply the ref count + 1
              of that page. If a contiguous group of pages has the same reference count, then at the starting page
              index of the chunk, the int stored is equivalent to -1(ref_count + 1), and the next int is the size
              of the chunk.
            1. (void)pp_getreflen(int *ppref, int offset, int *refp, int *lenp)
                * get the reference and length for a specific offset(basically by the book implementation
                  of description above)
                    => ppref's amap must be locked
                1. if ppref[offset] > 0, by the above description we are dealing with a length 1 chunk
                    i. set *refp = ppref[offset] - 1
                   ii. set *lenp = 1 
                2. else, this is a multi-length chunk  
                    i. set *refp = (ppref[offset] * -1) - 1
                   ii. set *lenp = ppref[offset + 1] 
            2. (void)pp_setreflen(int *ppref, int offset, int ref, int len) 
                * set the reference and length for a specific offset(basically by the book implementation
                  of description above)
                    => ppref's amap must be locked
                1. if len == 1, this is a single length chunk
                    i. set ppref[offset] == ref + 1
                2. else this is a multi-length chunk
                    i. set ppref[offset] = (ref + 1) * -1
                   ii. set ppref[offset + 1] = len
|-- uvm_amap.h
    * Split into machine dependent and machine independent parts. Contains
      prototypes and ds for uvm_amaps. vm_amaps are meant to be indirectly accessed,
      i.e. only use API funcs on the struct. 
        - UVM_AMAP_PPREF 
            1.enable to track split references so that we don't lose
              track of reference during partial unmaps
        - API flags
            1. AMAP_SHARED  - amap is shared    
            2. AMAP_REFALL  - used in amap_ref, reference an entire amap
            3. AMAP_SWAPOFF - used in amap_swap_off is in progress 
        - vm_amap_chunk is a structure for managing vm_anons in an amap
          Entries in a vm_amap are called slots. The slots of an amap are clustered into
          chunks of UVM_AMAP_CHUNK slots each. Every chunk contains an array of pointers to 
          vm_anon, and a bitmap is used to represent which of the slots are in use. 
            1. Is an entry in a tail queue called ac_list
            2. ac_baseslot - the slot # of anon located at ac_anon[0]
            3. ac_usedmap  - ? 
            4. ac_nslot    - # of slots in the chunk 
            5. ac_anon     - array of vm_anon ptrs
        - vm_amap is a structure representing an amap. 
            1. am_lock  - rwlock protexting vm_amap flags
            2. am_ref   - ref count
            3. am_flags - flags, unsure which ? 
            4. am_nslot - # of slots currently in map
            5. am_nused - # of slots currently in use
            6. am_ppref - per page reference count (only compiled in if UVM_AMAP_PPREF)
            7. is an entry in a list called am_list
            8. ami_impl - union of two structs representing storage type for amap
                i. ami_normal is a struct for an amap with >UVM_AMAP_CHUNK slots.
                    a. amn_buckets      - hash table impl
                    b. amn_chunks       - tail queue of amn_chunks
                    c. amn_nbuckets     - # of buckets 
                    d. amn_ncused       - # number of chunks currently in use
                    e. amn_hashshift    - shift count to hash slot to bucket
               ii. ami_small is a vm_amap_chunk used when <=UVM_AMAP_CHUNK
        - macros am_x = am_impl.ami_normal.x
        - UVM_AMAP_LARGE/UVM_AMAP_CHUNK 
            1. # of slots in a large map / # of slots to chunk large amaps in
        - UVM_AMAP_SMALL(amap)              - test if amap is a small amap
        - UVM_AMAP_SLOTIDX(slot)            - gives chunk that a slot is in
        - UVM_AMAP_BUCKET(amap,slot)        - finds bucket for slot in amap
        - AMAP_B2SLOT(S,B)                  - convert byte offset to slot
        - AMAP_CHUNK_FOREACH(chunk, amap)   - loops through each chunk in an amap
        - AMAP_BASE_SLOT(slot)              - gets base slot for chunk that a slot is in(nearest multiple of 
                                              UVM_AMAP_CHUNK <= slot) 
        - amap_flags(amap)                  - gets flags for an amap
        - amap_refs(amap)                   - gets refs for an amap
        - amap_lock(amap)                   - locks the amap
        - amap_unlock(amap)                 - unlocks the amap
|-- uvm_anon.c
    * Contains implementation of the prototypes in uvm_anon.h
        - Anons are allocated in a file static pool uvm_anon_pool
        - (void)uvm_anon_init(void) 
            * API method initing the anon subsystem
            1. uvm_anon_pool is initialized here
            2. anon_pool has a high watermark of uvmexp.free/16 
        - (struct vm_anon *)uvm_analloc(void) 
            * API method for allocating a new anon
            1. gets a new anon from the global pool
                i. an_lock = NULL
               ii. an_ref  = 1  
                    - process calling uvm_analloc is implicitly adding a ref
              iii. an_page = NULL
               iv. an_swslot = 0
        - (void)uvm_anfree_list(struct vm_anon *, struct pglist *)
            * API method for freeing a single anon structure
                => anon must be removed from the amap (if anon was in an amap)  
                => amap must be locked, if anon was owned by amap.
                => this func may lock the pageq's
            1. If underlying page is resident, we discard of it
                i. If the page has PG_BUSY set, we mark it PG_RELEASED and add a ref
                   to an_lock. Then RETURN 
               ii. We set the page's pmap protection to none across all pmaps. This
                   dereferences the page with respect to pmaps. 
              iii. If the pglist is not null, we clean it(remove from backing obj, tho not free)
                   and insret into pglist for later freeing  
               iv. Else we just free the page
            2. Else, we check if an_swslot is nonzero or not equal to SWSLOT_BAD, which means
               it is not in swap, and must be removed.
            3. Clear an_lock
            4. Free swap resources
            5. put anon back in pool
        - (void)uvm_anfree(struct vm_anon *) = uvm_anfree_list(struct vm_anon *, NULL)
        - (void)uvm_anwait(void)
            * API method for waiting for memory to become available to allocate an anon
            1. get an anon and put it back
        - (boolean_t)uvm_anon_pagein(struct vm_amap *, struct vm_anon *)
            * API method for fetchin an anon's page
                => anon msut be locked, and is unlocked at return
                => true if pagein was aborted(occurs due to lack of RAM), false otherwise
            1. Call uvmfault_anonget on the amap and anon, and store return value                     
            2. If VM_PAGER_OK
                i. Mark page as dirty(clear PAGE_CLEAN) and clear its swap_slot(uvm_swap_free)
               ii. Clear pmap refs and set pmap protection of page to PROT_NONE(pmap_clear_reference
                   and pmap_page_protect)
              iii. Deactivate page(uvm_pagedeactivate)
               iv. Release an_lock(rw_exit)
            3. Else, return FALSE ***I believe this should be If VM_PAGER_AGAIN, return TRUE***
        - (void)uvm_anon_dropswap(struct vm_anon *)
            * release any swap resources from this anon.
                => anon must be locked or have ref count of 0
            1. if we don't have a swap slot, return
            2. free swap slot (uvm_swap_free)
            3. set an_swslot = 0
        - (void)uvm_anon_release(struct vm_anon *)
            * release an anon and its page
                => anon should not have any references
                => anon must be locked
            1. Clear pmap refs and set pmap protection of page to PROT_NONE(pmap_clear_reference
               and pmap_page_protect)
            2. Free page (uvm_pagefree)
            3. Save an_lock in a tmp var
            4. Free vm_anon (uvm_anfree) 
            5. Release an_lock (rw_exit)
            6. Drop a ref on an_lock(rw_obj_free)
|-- uvm_anon.h
    * Contains prototypes of uvm anon and aref funcs and ds. The data can be in the
      following states. (1) in a vm_page with no backing store allocated yet, (2)
      in a vm_page with backing store, or (3) paged out to backing store with no
      vm_page in RAM
        - Vm_anon is a structure used to describe a page of anonymous(short term)
          memory that will go away when processes are done referencing it
            1. an_lock - rwlock protectnig this anon
            2. an_page - vm_page backing this anon if it is in ram 
            3. an_ref - # of processes referencing this anon 
            4. an_swslot - Drum swap slot # (used for swap space API)
        - Vm_aref is used to reference an anonymous virtual memory map(amap.h)  
            1. ar_pageoff - page offset into the anonymous map
            2. ar_amap - the backing amap 
|-- uvm_aobj.c
|-- uvm_aobj.h
    * Contains prototypes for a uvm anonymous object funcs, which is a backing object
      for anonymous memory(contains no ds)
|-- uvm_ddb.h
    * Contains print functions prototypes for DDB though unsure where those are defined
|-- uvm_device.c
|-- uvm_device.h
    * Contains prototypes of funcs and ds for uvm_device 
        - uvm_device is a device handle into the VM system.
            1. u_obj - backign uvm object
            2. u_flags - flags(I think below) 
                i. UVM_DEVICE_HOLD      - a process or thread has a hold on the device
               ii. UVM_DEVICE_WANTED    - a process or thread wants a hold on the device
            3. u_device - a struct representing the device
            4. u_list - global list of device objects
|-- uvm_extern.h
    * Unsure, but I believe this file provides an externel interface to the kernel
      of the uvm library.
        - PROT_MASK         - (PROT_READ | PROT_WRITE | PROT_EXEC) mask for protection 
        - MAP_INHERIT_MASK  - mask that can be used to find inheritance
        - MADV_MASK         - mask for advice
        - Flags for uvm_maps 
            1. UVM_FLAG_FIXED      - find space
            2. UVM_FLAG_OVERLAY    - establish overlay 
            3. UVM_FLAG_NOMERGE    - don't merge map entries 
            4. UVM_FLAG_COPYONW    - set copy_on_write flag 
            5. UVM_FLAG_TRYLOCK    - fail if we cannot lock map 
            6. UVM_FLAG_HOLE       - no backend 
            7. UVM_FLAG_QUERY      - do everything except actual execution 
            8. UVM_FLAG_NOFAULT    - don't fault 
            9. UVM_FLAG_UNMAP      - unmap to make space 
           10. UVM_FLAG_STACK      - page may contain a stack 
           11. UVM_FLAG_WC         - write combining 
           12. UVM_FLAG_CONCEAL    - omit from dumps 
           13. UVM_FLAG_SYSCALL    - system calls allowed 
           14. UVM_FLAG_SIGALSTACK - sigalstack validation required 
        - Macros to extract/put flag info in map(from and to flags entry)
            1. UVM_PROTECTION    (flags)    - extract protection info using PROT_MASK
            2. UVM_INHERIT       (flags)    - extract inherit info using MAP_INHERIT_MASK
            3. UVM_MAXPROTECTION (flags)    - extract maximum protection using PROT_MASK
            4. UVM_ADVICE        (flags)    - extract advice using MADV_MASK 
            5. UVM_MAPFLAG                  - take prot, maxprot, inheritance, advice, and other flags
                                              and create a flag bit array for use in map 
        - UVM_UKNOWN_OFFSET - offset not known to object
        - uvm_km_kmemalloc flags 
            1. UVM_KMF_NOWAIT   - matches M_NOWAIT
            2. UVM_KMF_VALLOC   - allocate VA only(VA?) 
            3. UVM_KMF_CANFAIL  - caller handles failure 
            4. UVM_KMF_ZERO     - zero pages 
            5. UVM_KMF_TRYLOCK  - try locking only 
        - uvm_pagealloc flags 
            1. UVM_PGA_USERESERVE - ok to use reserve pages
            2. UVM_PGA_ZERO       - returned page must be zeroed 
        - uvm_pglistalloc/uvm_pmr_getpages flags 
            1. UVM_PLA_WAITOK       - may sleep
            2. UVM_PLA_NOWAIT       - will not sleep(need this or above, not both)
            3. UVM_PLA_ZERO         - zero all pages before returning
            4. UVM_PLA_TRYCONTIG    - try to allocate contig physmem
            5. UVM_PLA_FAILOK       - caller will handle failures 
            6. UVM_PLA_NOWAKE       - do not wake pagedaemon on failure 
            7. UVM_PLA_USERESERVE   - can allocate from kernel reserve memory 
        - lockfalgs that control locking behaviour for some functions
            1. UVM_LK_ENTER - map locked on entry
            2. UVM_LK_EXIT  - leave map locked on exit 
        - flags to uvm_page_physload
            1. PHYSLOAD_DEVICE - don't add to the page queue 
        - vmspace is a struct representing a shareable process virtual
          address space. May eventually be merged with vm_map.
          several fields are temporary. 
            1. vm_map           - this space's vm_map
            2. vm_refcnt        - reference count, protected by kernel lock 
            3. vm_shm           - SYS5 shared memory of private data 
            4. vm_rssize        - current resident size in pages 
            5. vm_swrss         - resident set size before last swap 
            6. vm_tsize         - text size in pages 
            7. vm_dsize         - data size in pages 
            8. vm_dused         - data segment length in pages 
            9. vm_ssize         - stack size in pages, protected by vm_map lock
           10. vm_taddr         - user virtual address of text, immutable
           11. vm_daddr         - user virtual address of data, immutable
           12. vm_maxsaddr      - user VA at max stack growth 
           13. vm_minsaddr      - user VA at top of stack 
           14. vm_execve        - execve systemcall stub region, protected by vm_map lock
           15. vm_execve_end    - execve systemcall stub region end, protected by vm_map lock
        - uvm_constraint_range are structures that allow MD code to setup constraint ranges for 
          memory allocators, the primary use for this is to keep allocation for certain memory
          consumers such as mbuf pools within address ranges that are reachable by devices that
          perform DMA. It is alos to discourage memory allocations from being satisfied from ranges
          such as the ISA memory range, if they can be satisfied with allocation from other ranges.
            1. ucr_low  - low constraint
            2. ucr_high - high constraint
        - md-code defined external constraint ranges
            1. isa_constraint       - constraint range for ISA memory
            2. dma_constraint       - constraint range for DMA memory
            3. no_constraint        - no constraint? 
            4. uvm_md_constraints   - array of constraints, not sure? 
        - kernel maps owned by md code, defined externally (unsure about these)
            1. exec_map 
            2. kernel_map
            3. kmem_map
            4. phys_map
        - kmem_va_mode is a struct defining the allocation mode for a virtual space
            1. kv_map        - pinter to the ponter the the map we're allocating from
            2. kv_align      - alignment
            3. kv_wait       - wait for free space in the map if it's full. The default
                               allocators don't wait since running out of space in kernel_map and 
                               kmem_map is usually fatal. Special maps like exec_map are specifically
                               limited, so waiting for space in them is necessary
            4. kv_singlepage - use the single page allocator
            5. kv_executable - map the physical pages with PROT_EXEC 
        - kmem_pa_mode is a struct defining the allocation mode for a physical pages 
            1. kp_constraint - allocation constraint for physical pages
            2. kp_object     - if the pages should be allocated from an object
            3. kp_align      - physical alignment of the first page in the allocation 
            4. kp_boundary   - boundary that the physical addresses can't cross if the allocation is 
                               contiguous 
            5. kp_nomem      - don't allocate any backing pages
            6. kp_maxseg     - maximal amount of contiguous segments
            7. kp_zero       - zero the returned memory
            8. kp_pageable   - allocated pageable memory
        - kmem_dyn_mode is a struct holding dynamic allocation paramters. Stuff that changes too often or too
          much to create separate va and pa modes for. 
            1. kd_prefer   - offset to fee to PMAP_PREFER
            2. kd_waitok   - is it ok to sleep?
            3. kd_trylock  - don't sleep on map locks 
            4. kd_slowdown - special parameter for the singlepage va allocator that tells
                             the caller to sleep if possible to let the singlpage allocator
                             allocator catch up. 
        - extern defs for kmem_va_mode
            1. kv_any
            2. kv_intrsafe
            3. kv_page
        - extern defs for kmem_pa_mode
            1. kp_dirty
            2. kp_zero
            3. kp_dma
            4. kp_dma_contig
            5. kp_dma_zero
            6. kp_pageable
            7. kp_none
        - extern defs for kmem_dyn_mode
            1. kd_waitok
            2. kd_nowait
            3. kd_trylock
|-- uvm_fault.c
|-- uvm_fault.h
    * Contains the arguments to the fault handler and fault func prototypes, though
      unsure how these are connected to eachother
        - 3 types of faults
            1. VM_FAULT_INVALID - invalid mapping
            2. VM_FAULT_PROTECT - access does not match protection
            3. VM_FAULT_WIRE    - wire mapping?  
        - uvm_faultinfo is the argument struct to the fault handler
            1. orig_map - the original faulting map
            2. orig_rvaddr - original rounded addr where fault occurred 
            3. orig_size - original size of fault
            4. map - map, could be a submap 
            5. mapv - map's version # 
            6. entry - faulting entry of map 
            7. size - size of interest
|-- uvm_glue.c
|-- uvm_glue.h
    * Defines two function prototypes and no ds. More explanation in uvm_glue.c
|-- uvm_init.c
|-- uvm_io.c
|-- uvm_km.c
|-- uvm_km.h
    * Contains prototypes of funcs and ds for kernel virtual memory
      management. 
        - Uvm_km_free_page are structures that define a linked list
          of some kind, though they don't appear to have any other
          fields.
        - Uvm_km_pages is a global structure for managing uvm kernel pages
            1. mtx - a mutex protecting the global struct
            2. lowat/hiwat - low and high address watermarks(I think this means min and max?)
            3. free / page - I believe page is an array of addresses of kernel pages and 
               free is how many pages are free.
            4. freelist / freelistlen - linked list of uvm_km_free_page structs though I don't know
               how these work.
            5. km_proc - process that manages kernel memory?
|-- uvm_map.c
|-- uvm_map.h
    * Contains prototypes of vm_map and vm_map_entry ds and funcs
        - Vm_map_entries are structures containing entries in a vm_map.
            1. daddrs - a union between a red-black tree entry (addr_entry) and
                        a single list entry (addr_kentry). 
                i. addr_entry   - connects this vm_map_entry to a red_black tree sorted by addrs. Used when
                                  this entry is for a userland vm_map
               ii. addr_kentry  - connects this vm_map_entry to an singlely linked list. Used for kernel vm_map
                                  entries. 
            2. dfree - a union between a red-black tree entry (rbtree), a tail queue entry (tailq), and another
                       tail queue entry(deadq)
                i. rbtree       - connects this vm_map_entry to a red_black tree sorted by free space size.
               ii. tailq        - connects this vm_map_entry to a tail queue, unsure of purpose
              iii. deadq        - connects this vm_map_entry to a tail queue, known as the dead entry queue?
            3. start/end - start and end virtual addresses of the allocated region  
            4. guard     - number of bytes in guard, which separates each new allocations 
            5. fspace    - amount of free space in this entry
            6. object    - union between a uvm_obj(ubm_object) 
                           and sub_map(vm_map), since either can back an entry 
            7. offset    - offset into backing object
            8. aref      - anonymous overlay, pointer to an amap and offset into the amap
            9. etype     - entry type
                i. UVM_ET_OBJ           - it is a uvm_object
               ii. UVM_ET_SUBMAP        - it is a vm_map submap
              iii. UVM_ET_COPYONWRITE   - copy_on_write      
               iv. UVM_ET_NEEDSCOPY     - needs_copy         
                v. UVM_ET_HOLE          - no backend         
               vi. UVM_ET_NOFAULT       - don't fault        
              vii. UVM_ET_STACK         - this is a stack    
             viii. UVM_ET_WC            - write combining    
               ix. UVM_ET_CONCEAL       - omit from dumps    
                x. UVM_ET_SYSCALL       - syscall text segment
               xi. UVM_ET_IMMUTABLE     - entry may not be changed 
              xii. UVM_ET_FREEMAPPED    - map entry is on free list (DEBUG)
                - NOTE: VMMAP_FREE_START and VMMAP_FREE_END give the starting and ending addresses of free space
                        in an entry. These defs show that this can be derived from adding the guard to the end
                        address and adding the guard and fspace to the end respectfully, so the start and end
                        is what is currently allocated by the entry (ALL OF THIS COPIED FROM uvm.h DESC)
           10. protection     - protection code
           11. max_protection - max protection code
           12. inheritance    - inheritance type
           13. wired_count    - how many processes need this wired or how many pages are wired, unsure?
           14. advice         - madvise code
           15. flags          - flags for this object
                i. UVM_MAP_STATIC - static map entry
               ii. UVM_MAP_KMEM   - from kmem entry pool
           16. fspace_augment - max fspace in subtree
        - Vm_maps are rbtrees of free space and map entries
            1. uvm_map_addr - red black tree of entries sorted by address.
            2. NOTE: what is sserial and wserial?
            3. pmap - The physical map interface used by this vm_map
            4. size - size of space covered by map 
            5. ref_count - # of processes that need this map 
            6. flags 
                  i. VM_MAP_PAGEABLE      - entries are pageable
                 ii. VM_MAP_INTRSAFE      - entries are interrupt safe
                iii. VM_MAP_WIREFUTURE    - wire future entries 
                 iv. VM_MAP_BUSY          - map is busy 
                  v. VM_MAP_WANTLOCK      - want to write-lock 
                 vi. VM_MAP_GUARDPAGES    - add guard pages to map  
                vii. VM_MAP_ISVMSPACE     - map is a vmspace
               viii. VM_MAP_SYSCALL_ONCE  - libc syscall registered ? 
            7. timestamp - version number added after each change to signal when
               certain ops must restart 
            8. min/max offset - first and last addr over map entries
            9. b_start/b_end - beginning and end address for brk/heap allocation
           10. s_start/s_end - beginning and end address for stack allocation
           11. busy - point to the process holding busy on this map(can be NULL)
           12. uaddr_exe - address selector for the executable pages of memory. Used if protX
               is selected, or 'the pointer is not NULL'?
           13. uaddr_any - if the criteria for uaddr_exe is not fulfilled, these selectors
               are tried in the order they appear
           14. uaddr_brk_stack - selector for brk/stack area
           15. lock/mtx - rwlock which is non-interrupt safe and mtx which is interrupt safe.
           16. flags_lock - mutex for flags.
|-- uvm_meter.c
|-- uvm_mmap.c
|-- uvm_object.c
|-- uvm_object.h
    * Defines the prototypes and ds of the uvm_object module. 
        - uvm_objects represent a list of pages, which are managed by
          the object's pager. All pages that belong to an
          object are protected using it's lock.
            1. vmobjlock -  The lock may be shared amongst uvm objects. Lock
                            sharing is usually used when there is an undelrying object. 
                            For example. vnode representing a file may have an underlying
                            node, which is the case for tmpfs and layered file systems. In such a case, 
                            vnode's UVM object and the underlying UVM object shares the lock.
            2. pg_ops    - uvm_pager or this object's pages                  
            3. memt      - red-black tree of vm_pages of this object 
            4. uo_npages - # of pages in memt 
            5. uo_refs   - reference count for this object. The reference count is managed atomically for 
                           the anonymous UVM objects. For other objects. it is arbitrary 
                           (may use the lock or atomics).
        - UVM_OBJ_KERN is a 'special' uo_refs values which indicates that the object is a kernel memory
          object rather than a normal one (kernel memory objects don't have reference counts -- they
          never die). this value is used to detect kernel object mappings at uvm_unmap() time. normally
          when an object is unmapped its pages eventually become deactivated and then paged out and/or
          freed. this is not useful for kernel objects... when a kernel object is unmapped we always 
          want to free the resources associated with the mapping. UVM_OBJ_KERN allows us to decide which
          type of unmapping we want to do. in addition, we have kernel objects which may be used in an 
          interrupt context. these objects get their mappings entered with pmap_kenter and removed with
          pmap_kremove, which are safe to call in interrupt context, and must be used ONLY for wired kernel
          mappings in these objects and their associated maps.
        - UVM_OBJ_IS_KERN_OBJECT - macro that checks if an obj is a kern obj
        - extern const uvm_vnodeops/uvm_deviceops/pmap_pager/bufcache_pager are all the pagers
          defined throughout uvm
        - uvm_pagecmp - comparison function for objtree.
        - UVM_OBJ_IS_VNODE      - macro that detects if this object is a vnode
        - UVM_OBJ_IS_DEVICE     - macro that detects if this object is a device 
        - UVM_OBJ_IS_VTEXT      - macro that detects if this object is a vtext
        - UVM_OBJ_IS_AOBJ       - macro that detects if this object is a aobj
        - UVM_OBJ_IS_PMAP       - macro that detects if this object is a pmap
        - UVM_OBJ_IS_BUFCACHE   - macro that detects if this object is a bufcache 
        - UVM_OBJ_IS_DUMMY      - macro that detects if this object is a dummy
|-- uvm_page.c
|-- uvm_page.h
    * Contains prototypes of vm_page ds and funcs
        - Vm_pages are data structures kept
          for pages resident in memory. 
            1. Each page is an entry in globals: a page tail queue and 
               a red black tree referred to as the object tree.
            2. uanon - Anon page for anonymous memory(WHY?)
            3. uobject - backing object 
            4. offset - offset into object where page is 
            5. pg_flags - flags
                    i. PG_BUSY          - page is locked
                   ii. PG_WANTED        - page is being waited on 
                  iii. PG_TABLED        - page is in VP table(believe VP stands for Virtual Page) ? 
                   iv. PG_CLEAN         - page has not been modified since being paged in 
                    v. PG_CLEANCHK      - page clean bit has been checked 
                   vi. PG_RELEASED      - page released while paging 
                  vii. PG_FAKE          - page is not yet initialized 
                 viii. PG_RDONLY        - page must be mapped read-only 
                   ix. PG_ZERO          - page has been zero'd out  
                    x. PG_DEV           - page is in device space  
                   xi. PG_PAGER1        - pager specific flag 
                  xii. PQ_FREE          - page is in free list 
                 xiii. PQ_INACTIVE      - page is in inactive list 
                  xiv. PQ_ACTIVE        - page is in active list 
                   xv. PQ_ANON          - page is part of an anon rather than object 
                  xvi. PQ_AOBJ          - page is part of an anonymous object 
                 xvii. PQ_SWAPBACKED    - page is part of anon or anonymous object, i.e. it is
                                          backed by swap space. 
                xviii. PQ_ENCRYPT       - page needs encryption and decryption 
                  xix. PG_PMAPN         - flags reserved for pmaps with N in {0, ..., 5} 
            6. pg_version - version number incrememnted whenever page is modified
            7. wire_count - number of processes/threads that need this page wired into memory
            8. phys_addr - physical address of page
            9. fpgsz - free page range size 
           10. mdpage - machine dependent physical map page data
           11. owner/owner_tag - debugging fields for tracking which thread is using which page
        - Vm_physseg structures describe a physical memory segment
            1. start/end - PF# of first and (last + 1) page in segment (PF? I think this stands for Page Frame)
            2. avail_start/avail_end - PF# of first and (last + 1) free page in segment 
            3. pgs - vm_page structures matching each page from the start
            4. lastpg - vm_page structure matching the last page
        - Vm_page_zero_enable ?(defined externally)
        - Vm_physmem ?(defined externally)
|-- uvm_pager.c
|-- uvm_pager.h
    * Contains definition of uvm_pager interface
        - uvm_pagerops is a struct defining the operations a page
          must implement
            1. pgo_init         - void(void) func that inits the pager
            2. pgo_reference    - void(uvm_object) func that adds a ref to a uvm object 
            3. pgo_detach       - void(uvm_object) func that drops a ref to a uvm object 
            4. pgo_fault        - int(uvm_faultinfo *, ...) func that, if present, is used to
                                  perform specialized fault handling. Returns a status code 
                                  described below
            5. pgo_flush        - boolean_t(uvm_object, ...) func that flushes a page out of an object 
            6. pgo_get          - int(uvm_object, ...) func that gets/read page out of an object 
            7. pgo_put          - int(uvm_object, ...) func that put/writes page into an object 
            8. pgo_cluster      - void(uvm_object, ...) func that returns range of a cluster ?
            9. pgo_mk_pcluster  - vm_page**(uvm_object, ...) func that returns a "put" cluster?
        - flags for pager(mostly flush op)
            1. PGO_CLEANIT     - write dirty pages ot backing store
            2. PGO_SYNCIO      - if PGO_CLEANIT use sync I/O
            3. PGO_DEACTIVATE  - deactivate flushed pages 
            4. PGO_FREE        - free flushed pages 
            5. PGO_ALLPAGES    - flush whole object/get all pages
            6. PGO_DOACTCLUST  - flag to make mk_pcluster to include active pages 
            7. PGO_LOCKED      - fault data structures are locked [used for get]
            8. PGO_PDFREECLUST - daemon's free cluster flag [used for put]
            9. PGO_REALLOCSWAP - reallocate swap area [used for dropcluster?] 
           10. PGO_NOWAIT      - do not wait for inode lock
           11. PGO_DONTCARE    - for pages we are not interested in getting, used in get only 
        - flags to uvm_pagermapin
            1. UVMPAGER_MAPIN_WAITOK - allow waiting
            2. UVMPAGER_MAPIN_READ   - host <- device ? 
            3. UVMPAGER_MAPIN_WRITE  - device -> host (pseudo flag) ? 
        - get/put return values
            1. VM_PAGER_OK      - operation was successful 
            2. VM_PAGER_BAD     - specified data was out of the accepted range 
            3. VM_PAGER_FAIL    - specified data was in range, but doesn't exist 
            4. VM_PAGER_PEND    - operations was initiated but not completed 
            5. VM_PAGER_ERROR   - error while accessing data that is in range and exists 
            6. VM_PAGER_AGAIN   - temporary resource shortage prevented operation from happening 
            7. VM_PAGER_UNLOCK  - unlock the map and try again 
            8. VM_PAGER_REFAULT - [uvm_fault internal use only!] unable to relock data structures,
                                  thus the mapping needs to be reverified before we can proceed 
        - PAGER_MAP_SIZE - needed until the device strategy interface has changed to do physically addressed
                           I/O?
|-- uvm_param.h
    * Contains machine independent virtual memory parameters. 
        - boolean_t is defined here as an int
        - default page size is 4096
        - atop/ptoa - converts physical addresses to the page their in and
                      vice versa?
        - round_page / trunc_page - perform those operations on pages
|-- uvm_pdaemon.c
|-- uvm_pmap.h
    * Contains prototypes and ds to describe machine address mapping definitions 
      -- machine independent section
        - pmap_statistics is a struct allowing each machine dependent implementation
          to maintain expected statistics. They may do this anyway they choose, but are
          expected to return the statistics in this struct.
            1. resident_count - # of pages mapped total
            2. wired_count    - # of pages wired
        - flags passed to pmap_enter. Note the bottom 3 bits are PROT_* bits, used to
          indicate the access typw that was made (to seed modified and referenced 
          information).
            1. PMAP_WIRED   - wired mapping
            2. PMAP_CANFAIL - can fail if resource shortage
            3. PMAP_MDN     - machine dependent flags with N in {0, ..., 3} 
            4. PMAP_WC      - unknown?
        - Other interface functions, will most likely add here if needed
|-- uvm_pmemrange.c
|-- uvm_pmemrange.h
    * Contains prototypes and ds to describe and manage free physical memory 
        - global rbtrees of vm_pages, called uvm_pmr_add and uvm_pmr_size
        - page types
            1. UVM_PMR_MEMTYPE_DIRTY - this page may contain random data
            2. UVM_PMR_MEMTYPE_ZERO  - this page has been zeroed     
            3. UVM_PMR_MEMTYPE_MAX   - array size used below
        - uvm_pmemrange describes an address range of memory
            1. addr     - red-black tree of free page chunks, sorted by addr, uses uvm_pmr_addr_cmp
            2. size     - array of red-black trees of free page chunks, sorted by size, uses uvm_pmr_size_cmp. 
                          Uses UVM_PMR_MEMTYPE_MAX for size
            3. single   - array of tail queues of single page regions using pageq. 
                          Uses UVM_PMR_MEMTYPE_MAX for size
            4. low      - start of address range
            5. high     - end of address range + 1
            6. use      - use counter
            7. nsegs    - current range count
            8. uvm_pmemrange is an entry in a tail queue pmr_use sorted by use counter
            9. uvm_pmemrange is an entry in a red-black tree pmr_addr sorted by address
        - uvm_pmalloc is a struct containing a description of failing memory allocation.
          there are two ways new pages become available. (1) the page daemon drops them
          and (2) a process calls free. The buffer cache and page daemon can decide that
          they don't have the ability to make pages available in the requested range. In that case,
          the FAIL bit will be set. There's a possibility that a page is no longer on the queues
          but has not yet been freed, or that a page was busy. Also, wired pages are not considered
          for paging, so they could cause a failure that may be recoverable.
            1. entry in a tail queue named pmq
            2. pm_constaint/pm_size - allocation request paramters in the form of uvm_constraint range(defined in uvm_extern)
               and pm_size of constraint range
            3. pm_flags - state flags
                i. UVM_PMA_LINKED - uvm_pmalloc is on list
               ii. UVM_PMA_BUSY   - entry is busy with fpageq unlocked 
              iii. UVM_PMA_FAIL   - page daemon cannot free pages 
               iv. UVM_PMA_FREED  - at least one page in the range was freed 
        - Red-black tree named uvm_pmemrange_addr of uvm_pmemranges, uses uvm_pmemrange_addr_cmp.
        - Tail queue named uvm_pmemrange_use of uvm_pmemranges
        - uvm_pmr_control is a struct for controlling uvm_pmemranges
            1. addr - red-black tree of uvm_pmemranges sorted by addr
            2. use  - tail queue of uvm_pmemranges sorted by use? 
            3. allocs - tail queue of uvm_pmallocs.
|-- uvm_swap.c
|-- uvm_swap.h
    * Defines interface(func prototypes) to swap space?
        - SWCLUSTPAGES and SWSLOT_BAD defined here
|-- uvm_swap_encrypt.c
|-- uvm_swap_encrypt.h
    * Defines interface(func prototypes) to encrypted swap space?
        - Unknown flags?
            1. SWPENC_ENABLE
            2. SWPENC_CREATED
            3. SWPENC_DELETED
            4. SWPENC_MAXID
        - CTL_SWPENC_NAMES ?
        - SWAP_KEY_EXPIRE: time after that keys expire
        - SWAP_KEY_SIZE: 128 bit keys 
        - swap_key struct
            1. key      - 32 bit uint array of SWAP_KEY_SIZE, 'secret key for swap range'
            2. refcount - 16 bit uint, 'pages that still need it' 
        - unsure of this file???
|-- uvm_unix.c
|-- uvm_vnode.c
|-- uvm_vnode.h
    * Contains func prototypes and ds for vnode handle into VM system
        - uvm_vnode structure provides a handle for vnodes into UVM
            1. u_obj - backing vm object
            2. u_vnode - points back to owning vnode
            3. u_flags - flags for this object, guarded by u_obj's vmobjlock
                i. UVM_VNODE_VALID        - we are attached to the vnode
               ii. UVM_VNODE_CANPERSIST   - we can persist after ref == 0 
              iii. UVM_VNODE_ALOCK        - uvn_attach is locked out 
               iv. UVM_VNODE_DYING        - final detach/terminate in progress 
                v. UVM_VNODE_RELKILL      - uvn should be killed by releasepg
                                            when final i/o is done 
               vi. UVM_VNODE_WANTED       - someone is waiting for alock, dying,
                                            or relkill to clear
              vii. UVM_VNODE_VNISLOCKED   - underlying vnode struct is locked
                                            (valid when DYING is true)
             viii. UVM_VNODE_IOSYNC       - I/O sync in progress ... setter sleeps
                                            on &uvn->u_nio 
               ix. UVM_VNODE_IOSYNCWANTED - A process is waiting for the i/o sync to clear
                                            so it can do i/o. 
                x. UVM_VNODE_WRITEABLE    - uvn has pages that are writeable
               xi. UVM_VNODE_BLOCKED      - (UVM_VNODE_ALOCK|UVM_VNODE_DYING|UVM_VNODE_RELKILL) any condition
                                            that should block new processses from touching the vnode [set WANTED and sleep
                                            to wait for it to clear]
`-- uvmexp.h
    * Contains parts of UVM that can be exported, i.e. sysctl hooks
        - CTL_VM IDs
            1. VM_METER         - struct vmmeter
            2. VM_LOADAVG       - struct loadavg 
            3. VM_PSSTRINGS     - PSSTRINGS
            4. VM_UVMEXP        - struct uvmexp 
            5. VM_SAWPENCRYPT   - int
            6. VM_NKMEMPAGES    - int - # kmem_map pages
            7. VM_ANONMIN       - ?
            8. VM_VTEXTMIN      - ?
            9. VM_VNODEMIN      - ?
           10. VM_MAXSLP        - ?
           11. VM_USPACE        - ?
           12. VM_MALLOC_CONF   - config for userland malloc 
           13. VM_MAXID         - number of valid vm ids 
        - uvmexp is a struct containing global data structures that are exported to parts of
          the kernel other than the vm system
            1. vm_page constants fields
                i. pagesize     - size of a page, must be power of 2
               ii. pagemask     - page mask 
              iii. pageshift    - page shift 
            2. vm_page counters fields
                i. npages               - number of pages we manage, immutable
               ii. free                 - number of free pages, protected by uvm_lock_fpageq 
              iii. active               - number of active pages
               iv. inactive             - number of pages that we free'd but may want back 
                v. paging               - number of pages in the process of being paged out 
               vi. wired                - number of wired pages 
              vii. zeropages            - number of zero'd pages, protected by uvm_lock_fpageq 
             viii. reserve_pagedaemon   - number of pages reserved for pagedaemon 
               ix. reserve_kernel       - number of pages reserved for kernel     
                x. unused01             - formerly anonpages     
               xi. vnodepages           - # of pages used by vnode page cache     
              xii. vtextpages           - # of pages used by vtext vnodes         
            3. pageout params fields
                i. freemin      - min number of free pages
               ii. freetarg     - target number of free pages
              iii. inactarg     - target number of inactive pages
               iv. wiredmax     - max number of wired pages 
                v. anonmin      - min threshold for anon pages 
               vi. vtextmin     - min threshold for vtext pages
              vii. vnodemin     - min threshold for vnode pages
             viii. anonminpct   - min percent anon pages       
               ix. vtextminpct  - min percent vtext pages      
                x. vnodeminpct  - min percent vnode pages      
            4. swap fields           
                i. nswapdev     - number of configured swap devices in system, protected by uvm_swap_data lock
               ii. swpages      - number of PAGE_SIZE'ed swap pages in system, protected by uvm_swap_data lock
              iii. swpginuse    - number of swap pages in use, protected by kernel lock 
               iv. swpgonly     - number of swap pages in use, not also in RAM, protected by atomic operations
                v. nswget       - number of swap pages moved from disk to RAM, protected by atomic operations
               vi. nanon        - number of total anon's in system
              vii. unused05     - formerly nanonneeded 
             viii. unused06     - formerly nfreeanon   
            5. stat counters fields  
                i. faults           - page fault count
               ii. traps            - trap count      
              iii. intrs            - interrupt count 
               iv. swtch            - context switch count
                v. softs            - software interrupt count
               vi. syscalls         - system calls            
              vii. pageins          - pagine operation count  
             viii. unused07         - formerly obsolete_swapins
               ix. unused08         - formerly obsolete_swapouts
                x. pgswapin         - pages swapped in
               xi. pgswapout        - pages swapped out
              xii. forks            - forks
             xiii. forks_ppwait     - forks where parent waits
              xiv. forks_sharevm    - forks where vmspace is shared
               xv. pga_zerohit      - pagealloc where zero wanted and zero was available
              xvi. pga_zeromiss     - pagealloc where zero wanted and zero not available
             xvii. unused09         - formerly zeroaborts
            6. fault subcounters 
                i. fltnoram     - number of times fault was out of ram
               ii. fltnoanon    - number of times fault was out of anons 
              iii. fltnoamap    - number of times fault was out of amap chunks
               iv. fltpgwait    - number of times fault had to wait on a page 
                v. fltpgrele    - number of times fault found a released page 
               vi. fltrelck     - number of times fault relock called         
              vii. fltrelckok   - number of times fault relock is a success   
             viii. fltanget     - number of times fault gets anon page        
               ix. fltanretry   - number of times fault retrys an anon get    
                x. fltamcopy    - number of times fault clears "needs copy"   
               xi. fltnamap     - number of times fault maps a neighbor anon page
              xii. fltnomap     - number of times fault maps a neighbor obj page
             xiii. fltlget      - number of times fault does a locked pgo_get   
              xiv. fltget       - number of times fault does an unlocked get   
               xv. flt_anon     - number of times fault anon (case 1a)         
              xvi. flt_acow     - number of times fault anon cow (case 1b)
             xvii. flt_obj      - number of times fault is on object page (2a)
            xviii. flt_prcopy   - number of times fault promotes with copy (2b)
              xix. flt_przero   - number of times fault promotes with zerofill (2b)
            7. daemon counters 
                i. pdwoke       - number of times daemon woke up
               ii. pdrevs       - number of times daemon rev'd clock hand 
              iii. pdswout      - number of times daemon called for swapout 
               iv. pdfreed      - number of times daemon freed since boot 
                v. pdscans      - number of times daemon scanned since boot
               vi. pdanscan     - number of anonymous pages scanned by daemon 
              vii. pdobscan     - number of object pages scanned by daemon 
             viii. pdreact      - number of pages daemon reactivated since boot
               ix. pdbusy       - number of times daemon found a busy page     
                x. pdpageouts   - number of times daemon started a pageout     
               xi. pdpending    - number of times daemon got a pending pageout 
              xii. pddeact      - number of times daemon deactivates           
             xiii. unused11     - formerly pdreanon                            
              xiv. unused12     - formerly pdrevnode                           
             xiiv. unused13     - formerly pdrevtext                           
            8. fpswtch - FPU context switch
            9. kmapent - number of kernel map entries
        - _ps_strings is a struct for I'm assuming the PSSTRINGS VM_CTL flag above
            1. val - void* with uknown purpose ?
        - uvm_exp_counters is an enum denoting counter types
            1. stat counters
                i. faults   - page fault count
               ii. pageins  - pagein operation count 
            2. fault subcounters
                i. fltnoram     - number of times fault was out of ram
               ii. fltnoanon    - number of times fault was out of anons 
              iii. fltnoamap    - number of times fault was out of amap chunks
               iv. fltpgwait    - number of times fault had to wait on a page 
                v. fltpgrele    - number of times fault found a released page 
               vi. fltrelck     - number of times fault relock called         
              vii. fltrelckok   - number of times fault relock is a success   
             viii. fltanget     - number of times fault gets anon page        
               ix. fltanretry   - number of times fault retrys an anon get    
                x. fltamcopy    - number of times fault clears "needs copy"   
               xi. fltnamap     - number of times fault maps a neighbor anon page
              xii. fltnomap     - number of times fault maps a neighbor obj page
             xiii. fltlget      - number of times fault does a locked pgo_get   
              xiv. fltget       - number of times fault does an unlocked get   
               xv. flt_anon     - number of times fault anon (case 1a)         
              xvi. flt_acow     - number of times fault anon cow (case 1b)
             xvii. flt_obj      - number of times fault is on object page (2a)
            xviii. flt_prcopy   - number of times fault promotes with copy (2b)
              xix. flt_przero   - number of times fault promotes with zerofill (2b)
        3. exp_ncounters - no meaning given ?
0 directory, 44 files
